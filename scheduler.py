import time
import logging
import os
import requests
from datetime import datetime, timedelta
import pytz
from config import (
    SCHEDULE_INTERVAL_MINUTES, MAX_RETRIES, RETRY_DELAY_MINUTES,
    LOG_FILE, LOG_DIR, DATA_DIR, BACKUP_DIR
)
from scraper import scrape_aqi_data, get_tehran_time

TEHRAN_TZ = pytz.timezone('Asia/Tehran')

os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(BACKUP_DIR, exist_ok=True)

lg = logging.getLogger('AQI_Scheduler')
lg.setLevel(logging.DEBUG)

if not lg.handlers:
    fh = logging.FileHandler(LOG_FILE, encoding='utf-8')
    fh.setLevel(logging.DEBUG)
    
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    
    fmt = logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
    fh.setFormatter(fmt)
    ch.setFormatter(fmt)
    
    lg.addHandler(fh)
    lg.addHandler(ch)

lt_time = None
cf = 0
retry_times = {}


def check_site_health():
    """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØª Ø¢ÛŒØ§ UP Ø§Ø³Øª ÛŒØ§ DOWN"""
    try:
        response = requests.get('https://aqms.doe.ir/App/', timeout=5)
        return response.status_code == 200
    except:
        return False


def schedule_scraper():
    global lt_time, cf, retry_times
    
    lg.info("="*80)
    lg.info("ğŸš€ AQI Scheduler started")
    lg.info(f"ğŸ“… Schedule Interval: {SCHEDULE_INTERVAL_MINUTES} minutes")
    lg.info(f"ğŸ”„ Retry Logic: 3 attempts with 10-min intervals")
    lg.info(f"ğŸŒ Timezone: Asia/Tehran (UTC+03:30)")
    lg.info("="*80)
    
    while True:
        try:
            now = get_tehran_time()
            
            # ØªØ¹ÛŒÛŒÙ† Ø§Ú¯Ø± Ø¨Ø§ÛŒØ¯ Ø§Ø¬Ø±Ø§ Ø´ÙˆØ¯
            should_scrape = False
            if lt_time is None:
                should_scrape = True
            else:
                time_diff = (now - lt_time).total_seconds() / 60
                should_scrape = time_diff >= SCHEDULE_INTERVAL_MINUTES
            
            if should_scrape:
                lg.info("="*80)
                lg.info(f"â° [Main] Starting main scrape at {now.isoformat()}")
                lg.info("="*80)
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§ÛŒØª
                site_healthy = check_site_health()
                if not site_healthy:
                    lg.warning(f"ğŸš¨ [Main] Site is DOWN at {now.isoformat()}")
                else:
                    lg.info(f"âœ… [Main] Site is UP at {now.isoformat()}")
                
                success = False
                for attempt in range(1, MAX_RETRIES + 1):
                    attempt_time = get_tehran_time()
                    
                    if attempt == 1:
                        lg.info(f"ğŸ“ [Main] Attempt {attempt} at {attempt_time.isoformat()}")
                    else:
                        lg.info(f"ğŸ”„ [Retry] Attempt {attempt} at {attempt_time.isoformat()}")
                    
                    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡
                    result = scrape_aqi_data(attempt=attempt, max_attempts=MAX_RETRIES)
                    
                    if result and len(result) >= 20:
                        lg.info(f"âœ… [Main] Success: {len(result)} states collected at {attempt_time.isoformat()}")
                        success = True
                        cf = 0
                        lt_time = now
                        break
                    else:
                        if attempt < MAX_RETRIES:
                            # Ø²Ù…Ø§Ù† retry
                            retry_wait = RETRY_DELAY_MINUTES * 60
                            next_retry = attempt_time + timedelta(minutes=RETRY_DELAY_MINUTES)
                            lg.warning(f"âš ï¸  [Retry] Attempt {attempt} failed. Retrying in {RETRY_DELAY_MINUTES} minutes at {next_retry.isoformat()}")
                            
                            # Ø®ÙˆØ§Ø¨ Ú©Ø±Ø¯Ù† Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ø±Ø±Ø³ÛŒ
                            time.sleep(retry_wait)
                        else:
                            lg.error(f"âŒ [Retry] All {MAX_RETRIES} attempts failed at {attempt_time.isoformat()}")
                
                if not success:
                    cf += 1
                    lg.error(f"ğŸ”´ Consecutive failures: {cf}/{3}")
                    
                    if cf >= 3:
                        lg.critical(f"âš ï¸âš ï¸âš ï¸ {cf} consecutive failures! Site appears to be DOWN. Will retry at next scheduled time.")
            
            # Ø®ÙˆØ§Ø¨ 60 Ø«Ø§Ù†ÛŒÙ‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÙ†Ø§ÙˆØ¨ÛŒ
            time.sleep(60)
        
        except KeyboardInterrupt:
            lg.info("ğŸ›‘ Scheduler stopped (Ctrl+C)")
            break
        except Exception as e:
            lg.error(f"ğŸ’¥ Error: {e}", exc_info=True)
            time.sleep(60)



if __name__ == '__main__':
    schedule_scraper()
